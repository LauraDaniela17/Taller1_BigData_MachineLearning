---
title: "Taller 1 BDML"
author: Zeneth Olivero Tapia, Cristian Felipe Muñoz Guerrero, Laura Daniela Torres
  Diaz, Vivian Cabanzo Fernandez
date: "`r Sys.Date()`"
output: pdf_document
editor_options: 
  markdown: 
    wrap: sentence
---

## Configuración 

El primer bloque de código se utiliza para preparar el entorno de trabajo antes de iniciar el análisis de los datos.

1.  **Configuración de `knitr`**

2.  **Gestión de librerías con `pacman`**
    Se verifica si el paquete `pacman` está instalado y, en caso contrario, se instala.

3.  **Carga de librerías para el análisis**
    Cargue de librerías necesarias

```{r setup, include=FALSE}

# Configuración de knitr

knitr::opts_chunk$set(
	echo = TRUE,
	fig.align = "center",
	fig.height = 6,
	fig.width = 10,
	message = FALSE,
	warning = TRUE, 
	tidy = TRUE,               
  tidy.opts = list(width.cutoff = 60)  
)

```

```{r}
# Carga de paquetes para análisis, limpieza y manipulación de datos
# Instalar y cargar pacman (gestor de paquetes) y otras librerías para análisis de datos

if (!require("pacman")) install.packages("pacman")
library(pacman)
pacman::p_load(rvest, #Web scrapping
               dplyr, #Manipulación de datos
               tidyr, #Manipúlación de datos
               readr, #Lectura de archivos csv
               janitor, #Limpieza rapida 
               purrr, #Programación funcional
               skimr, #Resumén descriptivo
               tidyverse, #Manipulación de datos
               styler, #Estilo de código
               corrplot, #Matrices de correlación
               boot, #Bootstrap
               modelsummary, #Resuménes en tablas
               scales,  # Para formatear ejes
               gt, #Mejores tablas
               broom,  
               corrplot, #Matrices de correlación
               survey, #Manejo de encuestas complejas
               ggplot2, #Gráficas
               kableExtra, #Exportar tablas a Latex
               knitr,
               rio, #importar y exportar datos
               stargazer, # Estadísticas descriptivas
               gt, # Estadísticas descriptivas
               gtsummary,
               caret, # For predictive model assessment.
               gridExtra, # Arrange plots.
               labelled) #Para etiquetas

pacman::p_loaded()
```



##Web scraping


En este bloque se realiza la **extracción automática de los datos** de la Gran Encuesta Integrada de Hogares (GEIH) 2018 para Bogotá, disponible en el sitio web del profesor Ignacio Sarmiento:
<https://ignaciomsarmiento.github.io/GEIH2018_sample/>.

1.  **Generación de URLs de las paginaciones**
    Los datos se encuentran distribuidos en **10 páginas HTML**.
    Se construye un vector de URLs concatenando la dirección base con los números del 1 al 10.

2.  **Función de extracción de tablas**
    Se define la función `funcion_para_leer_tablas()` que:

    -   Lee el contenido HTML de cada página con `read_html()`.
    -   Selecciona la primera tabla encontrada en la página (`html_elements(...)[[1]]`).
    -   Convierte dicha tabla en un `data.frame` con `html_table()`.
    -   Limpia los nombres de las variables y ajusta los tipos de datos con `clean_names()` y `type_convert()`.

3.  **Unificación de los datos en una sola base**
    Se aplica la función a todas las URLs con `map_dfr()`, lo que permite **leer y combinar las 10 tablas en un único `data.frame` (`data_completa`)**.

En este primer apartado extraemos los datos de la página: : https://ignaciomsarmiento.
github.io/GEIH2018 sample/ , los cuales se encuentran distribuidos e 10 paginaciones

```{r cars}

# Generamos URL: contiene un vector de 10 paginaciones
urls <- paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_", 1:10, ".html")

funcion_para_leer_tablas <- function(a) {
  pagina <- read_html(a)  #Leer el html
  tabla_html <- html_elements(pagina, "table")[[1]] #Estrae la primera página
  data <- html_table(tabla_html, trim = TRUE)  #Convertir el html a data frame
  data <- data %>% clean_names() %>% type_convert() #Limpiar nombres y cambiar tipos de datos
  return(data)
}

data_completa <- map_dfr(urls, funcion_para_leer_tablas) #Aplica lo anterior para todas las 10 paginaciones 

cat("El dataset de la GEIH descargado de la página https://ignaciomsarmiento.github.io/GEIH2018_sample/  contiene", nrow(data_completa), "filas y", ncol(data_completa), "columnas.\n")

```

- Diccionario de datos

```{r}
urls2 <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/dictionary.html" #URL del diccionario de datos

data_diccionario <- funcion_para_leer_tablas(urls2) #Aplicamos la función para leer tablas
head(data_diccionario)

cat("El diccionario de variables contiene", nrow(data_diccionario), "filas y", ncol(data_diccionario), "columnas.\n")


```


## Revisión inicial de los datos

Revisión inicial de la estructuración de los datos:

cantidad de observaciones, tipos de datos, nombre de variables.


```{r}

## Revisión inicial:
# str para revisar la estructura de los datos
str(data_completa) #Vemos que hay una gran cantidad de NA y que los tipos mas comunes de datos son character, integrer, y numeral
# Names para identificar los nombres de todas las variables
names(data_completa) 
# head para ver las primeras observaciones
head(data_completa)
# tail para ver las ultimas   
tail(data_completa)

```

Una vez encontradas las variables de interés para la selección de la muestra, las cuales son age y ocu, procedemos a filtrar data_completa

```{r}
## Filtrar observaciones inferiores a los 18 años de edad y no ocupados
data_filter_inicial <- data_completa %>%
  filter(age >= 18)%>%filter(ocu==1)

# Revisamos nuevamente la cantidad de observaciones
cat("El dataset filtrado contiene", nrow(data_filter_inicial), "filas y", ncol(data_filter_inicial), "columnas.\n")
```

## Selección de variables

En este bloque se depura la base de datos filtrada (`data_filter`) para trabajar únicamente con las variables relevantes y se crea la variable de interés

Se conservan únicamente las siguientes 12 variables de interés:
- `directorio`, `secuencia_p`, `orden`: variables de identificación del individuo.
- `sex`: sexo.
- `age`: edad.
- `relab``: tipo de ocupacion.
- `mes`: mes en la que se realizó la encuesta.
- `formal`: formalidad del trabajo.
- `size_firm`: tamaño de la firma donde trabaja.
- `max_educ_level`: máximo nivel educativo alcanzado.
- `impa`: Ingreso monetario primera actividad antes de imputación.
- `hours_work_usual`: horas trabajadas usualmente por semana.

Creamos la variable dependiente de la siguiente manera: - **Númerador**: `impa` - **Denominador**: `hours_work_usual` \* 4.33 - Donde `4.33` corresponde al promedio de semanas en un mes (52 semanas / 12 meses).

```{r}
# Se seleccionan de data_filter_inicial las variables independientes seleccionadas para el análisis

data_filter <- data_filter_inicial %>%
  select(directorio, secuencia_p, orden,sex, age, relab, mes, formal,
         size_firm, max_educ_level, impa, hours_work_usual)

#Creación variable dependiente

data_filter <- data_filter %>%
  mutate(ingreso_hora_1 = (impa/(hours_work_usual*4.33)))

# Revisión nuevamente la cantidad de observaciones
cat("El dataset con las variables seleccionadas para el análisis contiene", nrow(data_filter), "filas y", ncol(data_filter), "columnas.\n")
```


## Segunda revisión de datos:

En esta sección se realizó una exploración preliminar de la base de datos con los siguientes objetivos:

1.  **Identificación de individuos únicos**
    -   Se construyó una llave de identificación (`id_individuo`) combinando variables como `directorio`, `secuencia_p` y `orden`.\
    -   Con esta llave se verificó cuántos individuos únicos había en la base, evitando duplicados accidentales.
2.  **Conteo de meses observados**
    -   Se revisó cuántos meses distintos aparecen en la información de la GEIH.\
    -   Esto permitió confirmar la cobertura temporal de los datos.
3.  **Seguimiento de individuos a lo largo del tiempo**
    -   Se verificó si un mismo individuo (`id_individuo`) aparece en varios meses.\
    -   De esta manera se buscó identificar casos de panel (individuos observados más de una vez) y diferenciarlos de observaciones transversales (solo un mes).

```{r}
# Análisis a nivel individuo:

# Revisamos cantidad de meses que hay en la base:
n_meses <- data_filter %>%
  summarise(total_meses = n_distinct(mes)) %>%
  pull(total_meses)  #12 meses

# Creamos el ID único para cada persona según la documentación de la GEIH
data_filter <- data_filter %>%
  mutate(id_individuo = paste(directorio, secuencia_p, orden, sep = "_"))

# Quitar duplicados a nivel individuo-mes
df_unicos <- data_filter %>%
  distinct(id_individuo, mes)

# Contar en cuántos meses aparece cada individuo
individuos_completos <- df_unicos %>%
  group_by(id_individuo) %>%
  summarise(n_meses_individuo = n_distinct(mes), .groups = "drop") %>%
  mutate(esta_en_todos = n_meses_individuo == n_meses)

# Número total de individuos únicos
total_individuos <- n_distinct(data_filter$id_individuo)

# Número de individuos que aparecen en todos los meses
n_en_todos <- sum(individuos_completos$esta_en_todos)

#Resultados a nivel individuo
list(
  total_individuos = total_individuos, #16.542 individuos
  meses_totales = n_meses, #12 meses
  individuos_en_todos_los_meses = n_en_todos #Ningún individuo se repite en ningún mes
)


```

## Revisión valores faltantes y ceros en la variable de ingreso

En este bloque de código se realiza un análisis exploratorio de los valores faltantes en la base de datos `data_filter`, siguiendo los pasos:

1.  **Identificación de valores faltantes**
    -   Se usa la función `skim()` para obtener un resumen de cada variable, extrayendo el número de valores faltantes (`n_missing`).
2.  **Cálculo del porcentaje de valores faltantes**
    -   Se obtiene el número total de observaciones (`Obs = nrow(data_filter)`).\
    -   Se calcula el porcentaje de valores faltantes para cada variable dividiendo `n_missing / Obs`.
3.  **Filtrado de variables relevantes**
    -   Se eliminan las variables que no presentan valores faltantes (`n_missing = 0`) para centrar el análisis solo en aquellas con datos ausentes.
4.  **Visualización gráfica**
    -   Se construye un gráfico de barras con `ggplot2` que muestra el **porcentaje de valores faltantes por variable**.\
    -   Se incluye:
        -   Ordenamiento de las variables de mayor a menor porcentaje de faltantes.
        -   Etiquetas con el porcentaje exacto sobre cada barra.

```{r}
# Revisamos valores faltantes:
data_miss <- skim(data_filter) %>% select( skim_variable, n_missing)

# Calculamos número de observaciones para despues calcular el porcentaje de NA
Obs <- nrow(data_filter) 
Obs #16.545 observaciones

#Porcentaje de observaciones faltantes
data_miss<- data_miss %>% mutate(p_missing= n_missing/Obs)

#Eliminar los que no tienen datos faltantes
data_miss<- data_miss %>% filter(n_missing!= 0)
head(data_miss)

```


```{r}
# Revisar los datos faltantes gráficamente:
ggplot(data_miss, aes(x = reorder(skim_variable, +p_missing) , y =  p_missing)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  coord_flip() +
  labs(title = "NA por variable", x = "Variable", y = "Porcentaje de NA")+ 
  theme(axis.text = element_text(size = 5))

# Revisión de ceros en la variable dependiente
# Contar observaciones con ingreso por hora  = 0
n_ceros <- sum(data_filter$ingreso_hora_1 == 0, na.rm = TRUE)

# Calcular el porcentaje de ceros respecto al total
p_ceros <- n_ceros / Obs


# Gráfico simple para visualizar ceros vs. positivos
data_filter %>%
  mutate(ingreso_cero = ifelse(ingreso_hora_1 == 0, "0", "Mayor a 0")) %>%
  count(ingreso_cero) %>%
  ggplot(aes(x = ingreso_cero, y = n, fill = ingreso_cero)) +
  geom_col(show.legend = FALSE, width = 0.6) +
  geom_text(aes(label = n), vjust = -0.5) +
  labs(
    title = "Distribución de ingresos iguales a 0 vs. mayores a 0",
    x = "Tipo de ingreso",
    y = "Observaciones"
  ) +
  theme_minimal(base_size = 12)


```


## Revisión de outliers (valores atípicos):

En este bloque se evaluó la presencia de **valores atípicos** en la variable `ingreso_hora`.

1.  **Cálculo de límites de referencia:**
    -   Se definieron los percentiles 1% y 99% como puntos de corte.
    -   Los valores por debajo del percentil 1% (`low`) y por encima del percentil 99% (`up`) fueron considerados potenciales outliers.
2.  **Visualización mediante boxplot:**
    -   Se construyó un boxplot de la variable `ingreso_hora`.
    -   Se añadieron dos líneas horizontales punteadas en color azul que marcan los límites de outliers (`low` y `up`).\
    -   Los valores atípicos fueron resaltados en color rojo dentro del gráfico.
  

```{r}
# Definimos límites inferior y superior de outliers usando percentiles
low <- quantile(data_filter$ingreso_hora_1, 0.01, na.rm = TRUE)   # Percentil 1%
up  <- quantile(data_filter$ingreso_hora_1, 0.99, na.rm = TRUE)   # Percentil 99%

# Mostramos los valores de referencia
low
up

# Crear boxplot para visualizar distribución de ingreso por hora (en log)
plot_outlier <- ggplot(data = data_filter, aes(x = "", y = ingreso_hora_1)) +
  geom_boxplot(fill = "skyblue", outlier.color = "red", outlier.size = 1) + # boxplot con outliers resaltados
  geom_hline(yintercept = low, color = "blue", linetype = "dashed", linewidth = 0.7) + # línea límite inferior
  geom_hline(yintercept = up,  color = "blue", linetype = "dashed", linewidth = 0.7) + # línea límite superior
  labs(
    title = "Boxplot de salario horario con límites de outliers",
    y = "Log(Ingreso por hora)",
    x = ""
  ) +
  theme_minimal()

# Mostrar el gráfico
print(plot_outlier)
```


## Manipulación final de datos

En esta etapa se realizaron dos procesos fundamentales:

1.  **transformación de variables categóricas:**
    Se identificaron aquellas variables que originalmente estaban codificadas con números enteros pero que representan categorías. Estas fueron convertidas a factores y se les asignaron etiquetas descriptivas para facilitar su interpretación.
    -   `sex` → `sexo`: recodificada como **Mujer** y **Hombre**.
    -   `formal`: clasificada en **Informal** y **Formal**.
    -   `Relab`: transformada en factor.
    -   `size_firm`: recodificada en categorías que representan el **tamaño de la empresa** (auto-empleado, 2–5 empleados, 6–10 empleados, 11–15 empleados y más de 50).
    -   `max_educ_level`: recodificada a niveles educativos alcanzados (ninguno, preescolar, primaria, secundaria, terciaria, N/A).
    
2. **Manipulación de los valores faltantes:**
    Para la variable `max_educ_level` se realizó una manipulación de su unico valor faltante mediante la imputación de su moda.
    
3.  **Tratamiento de la variable de ingresos:**
    -   Se eliminan las observaciones con **ingreso por hora igual a cero**, dado que no son válidas para el análisis de logaritmos y, además, podrían distorsionar la interpretación del salario.\
    -   Se crea la nueva variable `log_ingreso_hora`, que corresponde al **logaritmo natural del ingreso por hora**. Esta transformación ayuda a reducir la influencia de valores atípicos (outliers) y aproxima la distribución de la variable a una forma más cercana a la normalidad.


Previamente se revisan los niveles y etiquetas para clasificar las variables categoricas.

```{r}
#Revisar los niveles y etiquetas de las variables categoricas
levels <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/labels.html"

data_levels <- funcion_para_leer_tablas(levels)
head(data_levels)

cat("El diccionario de niveles y etiquetas contiene", nrow(data_levels), "filas y", ncol(data_levels), "columnas.\n")

```

```{r}
# Cambiar a factor las variables que son categóricas
data_filter <- data_filter %>%
  mutate(
    sex_label = factor(sex, 
                 levels = c(0, 1), 
                 labels = c("Mujer", "Hombre")),
    formal = factor(formal, 
                    levels = c(0, 1), 
                    labels = c("Informal", "Formal")),
    relab = factor(relab, 
                   levels = c(1,2,3,4,5,6,7,8,9),
                   labels = c("Empleado de empresa particular",
                              "Empleado del gobierno",
                              "Empleado domestico",
                              "Cuenta propia",
                              "Empleador",
                              "Sin remuneración (familiar)",
                              "Sin remuneración (No familiar)",
                              "Jornalero",
                              "Otro")), 
    size_firm = factor(size_firm,
                       levels = c(1, 2, 3, 4, 5),
                       labels = c("auto-empleado", 
                                  "2-5 empleados", 
                                  "6-10 empleados", 
                                  "11-15 empleados", 
                                  "Más de 15")),
    max_educ_level = factor(max_educ_level,
                            levels = c(1, 2, 3, 4, 5, 6, 7, 9),
                            labels = c("Ninguno", "Preescolar", "Primaria imcompleta", "Primaria completa", "Secundaria incompleta", "Secundaria completa", "Terciaria", "N/A")),
  )
```


```{r}
# Calcular la moda en la variable max_educ_level
moda <- names(sort(table(data_filter$max_educ_level), decreasing = TRUE))[1]

# Reemplazar los NA por la moda
data_filter$max_educ_level[is.na(data_filter$max_educ_level)] <- moda
data_filter$max_educ_level <- as.factor(data_filter$max_educ_level)

#Se eliminó el valor faltante en la variable
colSums(is.na(data_filter))
```


```{r}
# Manipulación de la variable ingreso por hora para reducción de peso de outliers
data_filter <- data_filter %>%
  filter(ingreso_hora_1> 0) %>%  # elimina ceros porque logaritmo no permite tener 0
  mutate(log_ingreso_hora = log(ingreso_hora_1))

colnames(data_filter)

```

Renombrar dataset final para analisis de los modelos de los puntos posteriores.

```{r}
datos_lim <- data_filter
```

## Estadísticas descriptivas de las variables


Se realizó un análisis descriptivo de las principales variables de interés de la base de datos.  
El objetivo fue comparar características socioeconómicas y laborales por sexo.

1.  Se incluyeron medidas de tendencia central y dispersión:  
   - Media  
   - Desviación estándar  
   - Diferencia de medias  
   - Error estándar de la diferencia
   
2. Para las variables categóricas (educación, formalidad y tamaño de la firma), se reportaron **frecuencias absolutas y porcentajes** en cada grupo.  

3. Gráficas descriptivas:
   - Gráfica de densidad del logaritmo del ingreso por hora para mujeres y hombres
   - Gráfica de violín para diferenciación entre niveles educativos
   - Gráfica boxplot para relacionar ingresos con modalidad de trabajo


```{r}

#Renombramos variables
data_labels <- data_filter %>%
  rename(
    "Ingreso por hora"= ingreso_hora_1,
    "Edad" = age,
    "Horas trabajadas"  = hours_work_usual,
    "Nivel educativo máximo"= max_educ_level,
    "Formalidad"= formal,
    "Tamaño de la firma"= size_firm,
    "Tipo de trabajo"= relab
  )

# Tabla de descriptivos
datasummary_balance(
  `Ingreso por hora` + Edad + `Horas trabajadas` +
    `Nivel educativo máximo` + Formalidad + `Tamaño de la firma` +
    `Tipo de trabajo` ~ sex_label,
  data = data_labels,
  fmt = 2,
  title = "Tabla de descriptivas"
)
```


```{r}

# Grafica de densidad
G_2 <- ggplot(datos_lim, aes(x = log_ingreso_hora, fill = sex_label)) +
  geom_density(alpha = 0.5) +
  labs(title = "Distribución del logaritmo del ingreso por hora por sexo",
       x = "Log(Ingreso por hora)", y = "Densidad", fill = "Sexo")

# Mostrar gráfico en R
print(G_2)

# Exportar a PDF
pdf("DistribucionLogIngresoxhora.pdf", width = 8, height = 6)
print(G_2)
dev.off()

```


```{r}

#Graficamos por violin
G_3 <- ggplot(datos_lim, aes(x = max_educ_level, y = log_ingreso_hora, fill = sex_label)) +
  geom_violin(alpha = 0.6, trim = FALSE, position = position_dodge(width = 0.9)) +  # violines por sexo
  geom_boxplot(width = 0.15, outlier.size = 0.8, alpha = 0.7, 
               position = position_dodge(width = 0.9)) + # boxplot dentro
  scale_fill_manual(values = c("Mujer" = "#E07B91", "Hombre" = "#6BAED6")) +
  labs(
    title = "Distribución del log(Ingreso por hora) según nivel educativo",
    subtitle = "Comparación entre hombres y mujeres",
    x = "Nivel educativo máximo alcanzado",
    y = "Log(Ingreso por hora)",
    fill = "Sexo"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, face = "italic"),
    axis.text.x = element_text(angle = 30, hjust = 1),
    legend.position = "top"
  )

# Mostrar gráfico en R
print(G_3)

# Exportar a PDF
pdf("VIOLIN.pdf", width = 8, height = 6)
print(G_3)
dev.off()

```

```{r}

#Graficamos con boxplot
G_4<-ggplot(datos_lim, aes(x = relab, y = log_ingreso_hora, fill = sex_label)) +
  geom_boxplot(alpha = 0.7, position = position_dodge(width = 0.9)) +
  scale_fill_manual(values = c("Mujer" = "#E07B91", "Hombre" = "#6BAED6")) +
  labs(
    title = "Log(Ingreso por hora) según tipo de trabajo",
    subtitle = "Comparación entre mujeres y hombres",
    x = "Tipo de trabajo",
    y = "Log(Ingreso por hora)",
    fill = "Sexo"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, face = "italic"),
    axis.text.x = element_text(angle = 25, hjust = 1),
    legend.position = "top"
  )

# Mostrar gráfico en R
print(G_4)

# Exportar a PDF
pdf("boxplot.pdf", width = 8, height = 6)
print(G_4)
dev.off()



```


# 3. Perfil edad-salario

$$
\ln(w) = \beta_1 + \beta_2 \cdot \text{age} + \beta_3 \cdot \text{age}^{2}+ u
$$
Crear la variable edad al cuadrado para el analisis
```{r}

# Se crea una nueva variable age2 que corresponde a la edad al cuadrado,
datos_lim <- datos_lim %>%
  mutate(age2 = age^2) %>%
  filter(complete.cases(age, log_ingreso_hora, age2))

# Se estima una regresión lineal donde la variable dependiente es
# el logaritmo del ingreso por hora y las independientes son
# la edad y la edad al cuadrado.
age_wage_reg <- lm(log_ingreso_hora ~ age + age2, data = datos_lim)

# resumen de la regresión
summary(age_wage_reg)


```

## Bootstrap

```{r}
# Se fija una semilla para que los resultados sean reproducibles.
set.seed(10101)

# Se extraen los coeficientes estimados de la regresión
b <- coef(age_wage_reg)

# Se calcula la edad en la que el ingreso es máximo.
peak_hat <- - b["age"] / (2 * b["age2"])

# Se define el número de réplicas (B) para un procedimiento de remuestreo,
B <- 1000 

# número de observaciones
n <- nrow(datos_lim)
n

```

```{r}
# Se fija una semilla
set.seed(10101)

# Se ejecuta un procedimiento de bootstrap para estimar la distribución
boot_peak <- replicate(B, {
  idx <- sample.int(n, size = n, replace = TRUE)
  fit <- lm(log_ingreso_hora ~ age + age2, data = datos_lim[idx, ])
  bb  <- coef(fit)
  if (is.na(bb["age2"]) || abs(bb["age2"]) < 1e-10) return(NA_real_) #control de errores
  - bb["age"] / (2*bb["age2"]) #calculo del pico
})

# Se eliminan los valores infinitos o NA de la distribución bootstrap,
boot_peak <- boot_peak[is.finite(boot_peak)]

```


```{r}
set.seed(10101)

# IC al 95% por percentiles del bootstrap (2.5% y 97.5%).
ci_perc <- quantile(boot_peak, c(0.025, 0.975), na.rm = TRUE)

# Percentiles sin nombres para evitar problemas de rownames
valid <- is.finite(boot_peak)
ci_perc <- quantile(boot_peak[valid], c(0.025, 0.975), na.rm = TRUE, names = FALSE)

# Muestra el intervalo [LI, LS].
ci_perc

```

```{r}

# Construir la tabla sin rownames
n_valid <- sum(is.finite(boot_peak))
tabla_peak <- data.frame(
  Estadistico = c("Edad pico (puntual)",
                  "IC 95% percentil (LI)",
                  "IC 95% percentil (LS)",
                  "Réplicas válidas"),
  Valor = c(peak_hat, ci_perc[1], ci_perc[2], n_valid),
  stringsAsFactors = FALSE,
  row.names = NULL
)
tabla_peak
```

# 4.Brecha Salarial de género

## 4.a Brecha incondicional

$$
\ln(w) = \beta_1 + \beta_2 \cdot \text{sex} + u
$$

```{r}
wage_gap <- lm(log_ingreso_hora ~ sex_label, data = datos_lim)

#Visualización de tabla

tidy(wage_gap, conf.int = TRUE) %>%
  mutate(term = recode(term, "(Intercept)" = "Intercepto", 
                       "sex_labelHombre" = "Sexo (1 = Hombre)")) %>%
  gt() %>%
  tab_header(
    title = "Estimación de Brecha Salarial",
    subtitle = "Modelo log-lineal sin controles"
  ) %>%
  fmt_number(columns = c(estimate, std.error, statistic, p.value, conf.low, conf.high), decimals = 2)



```

## 4.b Brecha condicional con controles

$$
\ln(w) = \beta_1 + \beta_2 \cdot \text{sex} + \theta X + u
$$

donde:

-   $w$: salario\
-   $\text{sex}$: variable binaria de sexo\
-   $X = \{ \text{edad}, \text{edad}^2, \text{educación}, \text{relab}, \text{formalidad}, \text{tamaño de empresa} \}$\
-   $u$: término de error aleatorio

```{r}
# Filtro de datos
gap_cond <- lm(log_ingreso_hora ~ sex_label + age + I(age^2) + max_educ_level + relab + formal + size_firm, 
             data = datos_lim)
#Visualización de tabla
tidy(gap_cond, conf.int = TRUE) %>%
  mutate(term = recode(term, 
    "(Intercept)" = "Intercepto",
    "sex_labelHombre" = "Sexo (1 = Hombre)",
    "age" = "Edad",
    "I(age^2)" = "Edad²",
    "max_educ_levelPrimaria imcompleta" = "Primaria incompleta",
    "max_educ_levelPrimaria completa" = "Primaria completa",
    "max_educ_levelSecundaria incompleta" = "Secundaria incompleta",
    "max_educ_levelSecundaria completa" = "Secundaria completa",
    "max_educ_levelTerciaria" = "Terciaria",
    "relabEmpleado del gobierno" = "Empleado público",
    "relabEmpleado domestico" = "Empleado doméstico",
    "relabCuenta propia" = "Cuenta propia",
    "relabEmpleador" = "Empleador",
    "relabJornalero" = "Jornalero",
    "relabOtro" = "Otro tipo de relación laboral",
    "formalFormal" = "Formalidad laboral",
    "size_firm2-5 empleados" = "Empresa: 2–5 empleados",
    "size_firm6-510 empleados" = "Empresa: 6–10 empleados",
    "size_firm11-15 empleados" = "Empresa: 11–15 empleados",
    "size_firmMás de 50" = "Empresa: más de 50 empleados"
)) %>%
  gt() %>%
  tab_header(
    title = "Estimación de Brecha Condicional con Controles",
    subtitle = "Modelo log-lineal con controles"
  ) %>%
  fmt_number(columns = c(estimate, std.error, statistic, p.value, conf.low, conf.high), decimals = 2)


```

## 4.b.i FWL (Frisch-Waugh-Lovell)

```{r}
# Paso 1: sex ~ X
res_sex <- lm(sex ~ age + I(age^2) + max_educ_level +
                 relab + formal + size_firm , 
              data = datos_lim)$residuals

# Paso 2: ln(w) ~ X
res_w <- lm(log_ingreso_hora ~ age + I(age^2) + max_educ_level +
              relab + formal + size_firm , 
            data = datos_lim)$residuals

# Paso 3: residuales
m_fwl <- lm(res_w ~ res_sex)
summary(m_fwl)

#Visualización de tabla
tidy(m_fwl, conf.int = TRUE) %>%
  mutate(term = recode(term, "(Intercept)" = "Intercepto")) %>%
  gt() %>%
  tab_header(
    title = "Estimación de Brecha Condicional con Controles",
    subtitle = "Modelo log-lineal con controles"
  ) %>%
  fmt_number(columns = c(estimate, std.error, statistic, p.value, conf.low, conf.high), decimals = 2)

# Interpretación en porcentaje
gap_fwl <- 100*(exp(coef(m_fwl)["res_sex"]) - 1)
gap_fwl  


```

## 4.b.ii FWL con bootstrap

```{r}


boot_fwl <- function(data, index){
  d <- data[index, ]
  r_sex <- lm(sex ~ age + I(age^2) + max_educ_level +
                 relab + formal + size_firm, 
              data = d)$residuals
  r_w   <- lm(log_ingreso_hora ~ age + I(age^2) + max_educ_level +
                 relab + formal + size_firm , 
              data = d)$residuals
  coef(lm(r_w ~ r_sex))[2]
}
 
set.seed(10101)
boot_res <- boot(data = datos_lim, statistic = boot_fwl, R = 1000)
boot.ci(boot_res, type="perc")

# Estimador FWL clásico
beta_fwl <- coef(m_fwl)["res_sex"]
se_fwl   <- summary(m_fwl)$coefficients["res_sex", "Std. Error"]

# Estimador FWL bootstrap
beta_boot <- mean(boot_res$t)
se_boot   <- sd(boot_res$t)

results <- data.frame(
  Metodo = c("FWL clásico", "FWL bootstrap"),
  Estimador = c(beta_fwl, beta_boot),
  SE = c(se_fwl, se_boot)
)
results
```


# 5. Predicción

Análisis de la tabla utilizada para verificar los modelos de prediccion 
```{r}
head(datos_lim)
```
```{r}
# Crear tabla con nombres de variables
tabla_variables <- data.frame(
  Numero = seq_along(names(datos_lim)),
  Nombre_Variable = names(datos_lim),
  stringsAsFactors = FALSE
)

# Mostrar tabla
print(tabla_variables)
```


```{r}
# Calcular el ancho de banda (binwidth) usando la regla de Scott
# Calcular el ancho de banda (binwidth) usando la regla de Scott
num_binwidth <- 3.5 * sd(datos_lim$ingreso_hora_1) / length(datos_lim$ingreso_hora_1)^(1/3)
num_binwidth <- round(x = num_binwidth, digits = 2)

# Crear el dataframe para las líneas
lineas <- data.frame(
  tipo = c("Mediana", "Media"),
  valor = c(median(datos_lim$ingreso_hora_1, na.rm = TRUE),
            mean(datos_lim$ingreso_hora_1, na.rm = TRUE))
)

# Graficar
a <- ggplot(datos_lim, aes(x = ingreso_hora_1)) +
  geom_histogram(
    aes(y = after_stat(count) / sum(after_stat(count))),
    binwidth = num_binwidth,
    fill = "sandybrown", color = "#FFFFFF", linewidth = 0.2,
    alpha = 0.8, closed = 'left', na.rm = TRUE
  ) +
  geom_vline(data = lineas, aes(xintercept = valor, color = tipo, linetype = tipo), linewidth = 0.9) +
  scale_color_manual(values = c("Mediana" = "darkturquoise", "Media" = "red")) +
  scale_linetype_manual(values = c("Mediana" = "solid", "Media" = "dashed")) +
  scale_y_continuous(
    expand = expansion(mult = c(0, 0.05)),
    labels = scales::label_number(scale = 100)
  ) +
  scale_x_continuous(expand = expansion(mult = c(0, 0)), limits = c(0, NA)) +
  labs(
    title = "Distribución del Ingreso por Hora (ingreso_hora_1)",
    x = "Ingreso por hora",
    y = "Porcentaje (%)",
    color = "Línea de referencia",
    linetype = "Línea de referencia"
  ) +
  theme_classic() +
  theme(
    legend.position = "top",
    legend.title = element_text(face = "bold")
  )

a

```

```{r}
# Calcular binwidth con la regla de Scott
num_binwidth <- 3.5 * sd(datos_lim$log_ingreso_hora) / length(datos_lim$log_ingreso_hora)^(1/3)
num_binwidth <- round(num_binwidth, 2)

# Crear dataframe con líneas de media y mediana
lineas_log <- data.frame(
  tipo = c("Mediana", "Media"),
  valor = c(
    median(datos_lim$log_ingreso_hora, na.rm = TRUE),
    mean(datos_lim$log_ingreso_hora, na.rm = TRUE)
  )
)

# Construir gráfico con leyenda
b <- ggplot(datos_lim, aes(x = log_ingreso_hora)) +
  geom_histogram(
    aes(y = after_stat(count) / sum(after_stat(count))),
    binwidth = num_binwidth,
    fill = "sandybrown", color = "#FFFFFF", linewidth = 0.2,
    alpha = 0.8, closed = 'left', na.rm = TRUE
  ) +
  geom_vline(data = lineas_log, aes(xintercept = valor, color = tipo, linetype = tipo), linewidth = 0.9) +
  scale_color_manual(values = c("Mediana" = "darkturquoise", "Media" = "red")) +
  scale_linetype_manual(values = c("Mediana" = "solid", "Media" = "dashed")) +
  scale_y_continuous(
    expand = expansion(mult = c(0, 0.05)),
    labels = scales::label_number(scale = 100)
  ) +
  scale_x_continuous(expand = expansion(mult = c(0, 0)), limits = c(0, NA)) +
  labs(
    title = "Distribución del Log Ingreso por Hora",
    x = "Log Ingreso Por hora",
    y = "Porcentaje (%)",
    color = "Línea de referencia",
    linetype = "Línea de referencia"
  ) +
  theme_classic() +
  theme(
    legend.position = "top",
    legend.title = element_text(face = "bold")
  )

b

```

Visualización de histogramas de salario por hora y logaritmo de salario por hora

```{r}
grid.arrange(a,b, nrow = 2)

# Exportar como PDF
pdf("hist_ingresos_comparados.pdf", width = 8, height = 8)
grid.arrange(a, b, nrow = 2)
dev.off()
```
como se observa en los histogramas, la distribucion de ingreso por hora tiene muy marcada la cola a la derecha, por esta razon se elegirá el logaritmo del ingreso por hora.

```{r}
skim(datos_lim)

```
```{r}
sapply(datos_lim, class)

```
## 5.a Muestra de entrenamiento y de prueba
Establecer Muestra de entrenamiento (70%) y de prueba (30%)

```{r}
# Semilla para replicabilidad
set.seed(10101)

# Crear partición de entrenamiento y prueba
inTrain <- createDataPartition(
  y = datos_lim$log_ingreso_hora,
  p = 0.70,
  list = FALSE
)

training <- datos_lim |> filter(row_number() %in% inTrain)
testing  <- datos_lim |> filter(!(row_number() %in% inTrain))

# Crear datos para visualización
split_data <- data.frame(
  Split = factor(c("Muestra de Entrenamiento", "Muestra de Prueba")),
  Count = c(nrow(training), nrow(testing)),
  Percentage = c(nrow(training)/nrow(datos_lim)*100, nrow(testing)/nrow(datos_lim)*100)
)

# CREAR EL GRÁFICO
grafico_split <- ggplot(split_data, aes(x = Split, y = Count)) +
  geom_bar(stat = "identity", fill = "darkturquoise", width = 0.5) +
  geom_text(aes(label = paste0(round(Percentage, 1), "%\n(n = ", Count, ")")),
            vjust = -0.5, color = "black", size = 4) +
  labs(title = "Distribución de la muestra de entrenamiento y de prueba",
       y = "Número de Observaciones",
       x = "") +
  scale_y_continuous(expand = expansion(mult = c(0, 0.2))) +
  theme_classic()

# MOSTRAR EN R
print(grafico_split)

# EXPORTAR A PDF
pdf("grafico_split_muestra.pdf", width = 8, height = 6)
print(grafico_split)
dev.off()

```

## 5.b Predicción en términos de RMSE
Poder de predicción de modelos en términos de RMSE, teniendo en cuenta tanto los 3 modelos anteriores como 5 modelos nuevos.

 - Validation Set Approach VSA - MODELO 1

$$
\ln(w) = \beta_1 + \beta_2 \cdot \text{age} + \beta_3 \cdot \text{age}^{2}+ u
$$

```{r}
form_1 <- log_ingreso_hora ~ age + I(age^2)
modelo1a <- lm(form_1,
               data = training)

predictions <- predict(object = modelo1a, newdata = testing)
score1a<- RMSE(pred = predictions, obs = testing$log_ingreso_hora )

cat("El RMSE del Modelo 1 es:", round(score1a, 4), "\n")
```
 - VSA - MODELO 2

$$
\ln(w) = \beta_1 + \beta_2 \cdot \text{sex} + u
$$
```{r}
form_2 <- log_ingreso_hora ~ sex
modelo2a <- lm(form_2,
               data = training )

predictions <- predict(object = modelo2a, newdata = testing)
score2a<- RMSE(pred = predictions, obs = testing$log_ingreso_hora )

cat("El RMSE del Modelo 2 es:", round(score2a, 4), "\n")
```
- VSA - MODELO 3

$$
\ln(w) =\beta_1 + \beta_2 \cdot \text{sex} + \beta_3 \cdot \text{age} + \beta_4 \cdot \text{age}^2 + \beta_5 \cdot \text{educ} + \beta_6 \cdot \text{relab} + \beta_7 \cdot \text{formal} + \beta_8 \cdot \text{size_firm} + u
$$



```{r}
form_3 <- log_ingreso_hora ~ sex + age + I(age^2) + max_educ_level +
               relab + formal + size_firm
modelo3a <- lm(form_3, data = training)
predictions <- predict(object = modelo3a, newdata = testing)
score3a <- RMSE(pred = predictions, obs = testing$log_ingreso_hora )

cat("El RMSE del Modelo 3 es:", round(score3a, 4), "\n")

```
 
 - VSA - MODELO 4

$$
\ln(w) = \beta_1 + \beta_2 \cdot \text{age} + \beta_3 \cdot \text{sex} + \beta_4 \cdot (\text{age} \cdot \text{sex}) + \beta_5 \cdot \text{age}^2 + \beta_6 \cdot \text{educ} + u
$$

```{r}
form_4 <- log_ingreso_hora ~ age * sex + I(age^2) + max_educ_level

modelo4a <- lm(form_4, data = training)
predictions <- predict(object = modelo4a, newdata = testing)
score4a <- RMSE(pred = predictions, obs = testing$log_ingreso_hora)

cat("El RMSE del Modelo 4 es:", round(score4a, 4), "\n")

```

 - VSA - MODELO 5

$$
\ln(w) = \beta_1 + \beta_2 \cdot \text{sex} + \beta_3 \cdot \text{educ} + \beta_4 \cdot (\text{sex} \cdot \text{educ}) + \beta_5 \cdot \text{age} + u
$$



```{r}
form_5 <- log_ingreso_hora ~ sex * max_educ_level + age
modelo5a <- lm(form_5,
               data = training )
predictions <- predict(object = modelo5a, newdata = testing)
score5a <- RMSE(pred = predictions, obs = testing$log_ingreso_hora )

cat("El RMSE del Modelo 5 es:", round(score5a, 4), "\n")

```

 - VSA - MODELO 6

$$
\ln(w) = \beta_1 + \beta_2 \cdot \text{age} + \beta_3 \cdot \text{relab} + u
$$


```{r}

form_6 <- log_ingreso_hora ~ age + relab
modelo6a <- lm(form_6,
               data = training )
predictions <- predict(object = modelo6a, newdata = testing)
score6a <- RMSE(pred = predictions, obs = testing$log_ingreso_hora )

cat("El RMSE del Modelo 6 es:", round(score6a, 4), "\n")
```

  - VSA - MODELO 7

$$
\ln(w) = \beta_1 + \beta_2 \cdot \text{age} + \beta_3 \cdot \text{formal} + \beta_3 \cdot \text{educ} + \beta_4 \cdot (\text{formal} \cdot \text{educ}) + u
$$

```{r}
form_7 <- log_ingreso_hora ~ age + formal * max_educ_level
modelo7a <- lm(form_7,
               data = training)

predictions <- predict(object = modelo7a, newdata = testing)
score7a <- RMSE(pred = predictions, obs = testing$log_ingreso_hora)

cat("El RMSE del Modelo 7 es:", round(score7a, 4), "\n")
```

 - VSA - MODELO 8

$$
\ln(w) = \beta_1 + \beta_2 \cdot \text{educ} + \beta_3 \cdot \text{relab} + \beta_3 \cdot (\text{educ} \cdot \text{relab}) + \beta_5 \cdot \text{age} + u
$$

```{r}
form_8 <- log_ingreso_hora ~ max_educ_level * relab + age
modelo8a <- lm(form_8,
               data = training )
predictions <- predict(object = modelo8a, newdata = testing)
score8a <- RMSE(pred = predictions, obs = testing$log_ingreso_hora )

cat("El RMSE del Modelo 8 es:", round(score8a, 4), "\n")
```


```{r}
# Crear data frame con los resultados
tabla_rmse <- data.frame(
  Modelo = paste("Modelo", 1:8),
  Dependiente = rep("Log Ingreso por hora", 8),
  Especificación_Modelo = c(
    "Edad + Edad²",
    "Sexo",
    "Sexo + Edad + Edad² + Educación + Tipo Ocupación + Formal + Tamaño empresa",
    "Sexo * Edad + Edad² + Educación",
    "Sexo * Educación + Edad",
    "Edad + Tipo Ocupación",
    "Edad + Educación * Formal",
    "Educación * Tipo Ocupación + Edad"
  ),
  RMSE = round(c(score1a, score2a, score3a, score4a, score5a, score6a, score7a, score8a), 4),
  stringsAsFactors = FALSE
)

# Ver tabla
print(tabla_rmse)

```


- K-FOLD
```{r}
ctrl <- trainControl(
  method = "cv", # Method for resampling. 
  number = 5) # Number of folds.
```

 - K-FOLD MODELO 1
```{r}
set.seed(10101)  
modelo1b <- train(
  form_1, # Define the functional form (i.e the variable to predict and the features).
  data = datos_lim, 
  method = 'lm', # Algorithm. In this case, linear model. 
  trControl = ctrl
)  
modelo1b
modelo1b$resample
score1b<- mean(modelo1b$resample$RMSE)
cat("El RMSE del Modelo 1 es:", round(score1b, 4), "\n")

```
 - K-FOLD MODELO 2
```{r}
set.seed(10101)  
modelo2b <- train(form_2,
                  data = datos_lim,
                  method = 'lm',
                  trControl= ctrl)
modelo2b
modelo2b$resample
score2b<- mean(modelo2b$resample$RMSE)
cat("El RMSE del Modelo 2 es:", round(score2b, 4), "\n")

```

- K-FOLD MODELO 3
```{r}
set.seed(10101)  
modelo3b <- train(form_3,
                  data = datos_lim,
                  method = 'lm',
                  trControl= ctrl)
modelo3b
modelo3b$resample
score3b<- mean(modelo3b$resample$RMSE)
cat("El RMSE del Modelo 3 es:", round(score3b, 4), "\n")
```


- K-FOLD MODELO 4
```{r}
set.seed(10101)  
modelo4b <- train(form_4,
                  data = datos_lim,
                  method = 'lm',
                  trControl= ctrl)
modelo4b
modelo4b$resample
score4b<- mean(modelo4b$resample$RMSE)
cat("El RMSE del Modelo 4 es:", round(score4b, 4), "\n")
```


- K-FOLD MODELO 5
```{r}
set.seed(10101)  
modelo5b <- train(form_5,
                  data = datos_lim,
                  method = 'lm',
                  trControl= ctrl)
modelo5b
modelo5b$resample
score5b<- mean(modelo5b$resample$RMSE)
cat("El RMSE del Modelo 5 es:", round(score5b, 4), "\n")

```


 - K-FOLD MODELO 6
```{r}
set.seed(10101)  
modelo6b <- train(form_6,
                  data = datos_lim,
                  method = 'lm',
                  trControl= ctrl)
modelo6b
modelo6b$resample
score6b<- mean(modelo6b$resample$RMSE)
cat("El RMSE del Modelo 6 es:", round(score6b, 4), "\n")

```

- K-FOLD MODELO 7
```{r}
set.seed(10101)  
modelo7b <- train(form_7,
                  data = datos_lim,
                  method = 'lm',
                  trControl= ctrl)
modelo7b
modelo7b$resample
score7b<- mean(modelo7b$resample$RMSE)
cat("El RMSE del Modelo 7 es:", round(score7b, 4), "\n")

```



 - K-FOLD MODELO 8
```{r}
set.seed(10101)  
modelo8b <- train(form_8,
                  data = datos_lim,
                  method = 'lm',
                  trControl= ctrl)
modelo8b
modelo8b$resample
score8b<- mean(modelo8b$resample$RMSE)
cat("El RMSE del Modelo 8 es:", round(score8b, 4), "\n")

```


## 5.c Resultados de los modelos

```{r}
## Dataframe de RMSE para comparar entre modelos
scores <- data.frame(Model= c(1, 2, 3, 4, 5, 6, 7, 8),
                    RMSE_vsa= c(score1a, score2a, score3a, score4a, score5a, score6a,
                                score7a, score8a), 
                    RMSE_kfold= c(score1b, score2b, score3b, score4b, score5b, score6b,
                                  score7b, score8b)
                    )

scores
```


## 5.d LOOCV

De acuerdo con los resultados de RMSE de Validation Set Approach y K-Fold se eligen los modelos 3 y 7, con el objetivo de verificar los resultados de RMSE por el método de LOOCV

```{r}
# LOOCV específico para Modelo 3

# Ajustar modelo completo con todos los datos
modelo3_full <- lm(form_3, data = datos_lim)

# Matriz de diseño X y vector respuesta y
X3 <- model.matrix(modelo3_full)
y3 <- model.response(model.frame(modelo3_full))

# Estimador de coeficientes (beta_hat)
beta_hat3 <- modelo3_full$coefficients

# Inversa de (X'X) 
G_inv3 <- solve(t(X3) %*% X3)

# Valores de leverage (h_ii)
vec3 <- 1 / (1 - hatvalues(modelo3_full))

# Número de observaciones
N3 <- nrow(X3)

# Vector para almacenar errores cuadráticos
LOO3 <- numeric(N3)

# Loop sobre cada observación
for (i in 1:N3) {
  # Coeficientes beta reestimados quitando la i-ésima observación
  beta_new3 <- beta_hat3 - vec3[i] * G_inv3 %*% as.vector(X3[i, ]) * modelo3_full$residuals[i]
  
  # Error cuadrático LOOCV para la observación i
  error_i3 <- (y3[i] - (X3[i, ] %*% beta_new3))^2
  LOO3[i] <- error_i3
}

# Calcular error promedio y su raíz cuadrada (RMSE)
error_promedio3 <- mean(LOO3)
rmse_loocv3 <- sqrt(error_promedio3)

# Imprimir resultado
cat("RMSE LOOCV del Modelo 3:", round(rmse_loocv3, 4), "\n")

```

```{r}
# LOOCV específico para Modelo 7

# Ajustar modelo completo con todos los datos
modelo7_full <- lm(form_7, data = datos_lim)

# Matriz de diseño X y vector respuesta y
X7 <- model.matrix(modelo7_full)
y7 <- model.response(model.frame(modelo7_full))

# Estimador de coeficientes (beta_hat)
beta_hat7 <- modelo7_full$coefficients

# Inversa de (X'X)
G_inv7 <- solve(t(X7) %*% X7)

# Valores de leverage (h_ii)
vec7 <- 1 / (1 - hatvalues(modelo7_full))

# Número de observaciones
N7 <- nrow(X7)

# Vector para almacenar errores cuadráticos
LOO7 <- numeric(N7)

# Loop sobre cada observación
for (i in 1:N7) {
  # Coeficientes beta reestimados quitando la i-ésima observación
  beta_new7 <- beta_hat7 - vec7[i] * G_inv7 %*% as.vector(X7[i, ]) * modelo7_full$residuals[i]
  
  # Error cuadrático LOOCV para la observación i
  error_i7 <- (y7[i] - (X7[i, ] %*% beta_new7))^2
  LOO7[i] <- error_i7
}

# Calcular error promedio y su raíz cuadrada (RMSE)
error_promedio7 <- mean(LOO7)
rmse_loocv7 <- sqrt(error_promedio7)

# Imprimir resultado
cat("RMSE LOOCV del Modelo 7:", round(rmse_loocv7, 4), "\n")

```
```{r}
## Store the RMSE in dataframe
ResultadosRMSE<- data.frame( Modelo = c(3, 7),
                    RMSE_vsa1= c(score3a, score7a), 
                    RMSE_kfold1= c(score3b, score7b),
                    RMSE_loocv1= c(rmse_loocv3,
                                   rmse_loocv7)
                    )

ResultadosRMSE
```

```{r}
## Visualización

RMSE_vsa2   <-  c(score3a, score7a) 
RMSE_kfold2 <-  c(score3b, score7b)
RMSE_loocv2 <-  c(rmse_loocv3, rmse_loocv7)


scores3 <- data.frame( Modelo = rep(c(3, 7),3),
                     Approach= c(rep("VSA",4),rep("K-Fold",4),rep("LOOCV",4)),
                     RMSE= c(RMSE_vsa2, RMSE_kfold2, RMSE_loocv2)
                    )

# Crear gráfico
RMSE <- ggplot(scores3) + 
  geom_line(aes(x = Modelo, y = RMSE, col = Approach), size = 0.8) +
  labs(
    title = "Comparación del RMSE entre los Modelos 3 y 7",
    x = "Modelo",
    y = "RMSE",
    color = "Método de Validación"
  ) +
  theme_bw() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    axis.title = element_text(face = "bold"),
    legend.title = element_text(face = "bold")
  )

# Mostrar gráfico en R
print(RMSE)

# Exportar a PDF
pdf("RMSE.pdf", width = 8, height = 6)
print(RMSE)
dev.off()

```

