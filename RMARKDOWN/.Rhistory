Count = c(nrow(training), nrow(testing)),
Percentage = c(nrow(training)/nrow(datos_lim)*100, nrow(testing)/nrow(datos_lim)*100)
)
# Create the visualization
ggplot(split_data, aes(x = Split, y = Count)) +
geom_bar(stat = "identity", fill = "darkblue", width = 0.5) +
geom_text(aes(label = paste0(round(Percentage, 1), "%\n(n=", Count, ")")),
vjust = -0.5, color = "black", size = 4) +
labs(title = "Train-Test Split Distribution",
y = "Number of Observations",
x = "") +
scale_y_continuous(expand = expansion(mult = c(0, 0.2))) + # Add some space for labels
theme_classic()
head(datos_lim)
names(datos_lim)
# Calculate the binwidth through Scott's rule.
num_binwidth <- 3.5 * sd(datos_lim$ingreso_hora_1) / length(datos_lim$ingreso_hora_1)^(1/3)
num_binwidth <- round(x = num_binwidth, digits = 2)
a<- ggplot(db, aes(x = ingreso_hora_1 )) +
geom_histogram(mapping = aes(y = (after_stat(count))/sum(after_stat(count))),
color ="#FFFFFF", fill= "#3a5e8cFF", show.legend = FALSE, na.rm = TRUE,
binwidth = num_binwidth, linewidth = 0.2, alpha = 0.8, closed = 'left') +
scale_y_continuous(expand = expansion(mult = c(0, 0.05)),
labels = scales::label_number(scale = 100)) +
scale_x_continuous(expand = expansion(mult = c(0, 0)), limits = c(0, NA)) +
labs(x = "Ingreso Hora 1", y = "Percent (%)") +
theme_classic()
# Calculate the binwidth through Scott's rule.
num_binwidth <- 3.5 * sd(datos_lim$ingreso_hora_1) / length(datos_lim$ingreso_hora_1)^(1/3)
num_binwidth <- round(x = num_binwidth, digits = 2)
a<- ggplot(datos_lim, aes(x = ingreso_hora_1 )) +
geom_histogram(mapping = aes(y = (after_stat(count))/sum(after_stat(count))),
color ="#FFFFFF", fill= "#3a5e8cFF", show.legend = FALSE, na.rm = TRUE,
binwidth = num_binwidth, linewidth = 0.2, alpha = 0.8, closed = 'left') +
scale_y_continuous(expand = expansion(mult = c(0, 0.05)),
labels = scales::label_number(scale = 100)) +
scale_x_continuous(expand = expansion(mult = c(0, 0)), limits = c(0, NA)) +
labs(x = "Ingreso Hora 1", y = "Percent (%)") +
theme_classic()
grid.arrange(a, nrow = 2)
num_binwidth <- 3.5 * sd(datos_lim$log_ingreso_hora) / length(datos_lim$log_ingreso_hora)^(1/3)
num_binwidth <- round(x = num_binwidth, digits = 2)
c <- ggplot(datos_lim, aes(x = log_ingreso_hora)) +
geom_histogram(mapping = aes(y = (after_stat(count))/sum(after_stat(count))),
color ="#FFFFFF", fill= "#3a5e8cFF", show.legend = FALSE, na.rm = TRUE,
binwidth = num_binwidth, linewidth = 0.2, alpha = 0.8, closed = 'left') +
scale_y_continuous(expand = expansion(mult = c(0, 0.05)),
labels = scales::label_number(scale = 100)) +
scale_x_continuous(expand = expansion(mult = c(0, 0)), limits = c(0, NA)) +
geom_vline(xintercept = median(db$ingtot, na.rm = TRUE), color = 'green', linetype = 'dashed') +
geom_vline(xintercept = mean(db$ingtot, na.rm = TRUE), color = 'red', linetype = 'dashed') +
labs(x = "Log Ingreso Por hora", y = "Percent (%)") +
theme_classic()
num_binwidth <- 3.5 * sd(datos_lim$log_ingreso_hora) / length(datos_lim$log_ingreso_hora)^(1/3)
num_binwidth <- round(x = num_binwidth, digits = 2)
c <- ggplot(datos_lim, aes(x = log_ingreso_hora)) +
geom_histogram(mapping = aes(y = (after_stat(count))/sum(after_stat(count))),
color ="#FFFFFF", fill= "#3a5e8cFF", show.legend = FALSE, na.rm = TRUE,
binwidth = num_binwidth, linewidth = 0.2, alpha = 0.8, closed = 'left') +
scale_y_continuous(expand = expansion(mult = c(0, 0.05)),
labels = scales::label_number(scale = 100)) +
scale_x_continuous(expand = expansion(mult = c(0, 0)), limits = c(0, NA)) +
geom_vline(xintercept = median(datos_lim$log_ingreso_hora, na.rm = TRUE), color = 'green', linetype = 'dashed') +
geom_vline(xintercept = mean(datos_lim$log_ingreso_hora, na.rm = TRUE), color = 'red', linetype = 'dashed') +
labs(x = "Log Ingreso Por hora", y = "Percent (%)") +
theme_classic()
num_binwidth <- 3.5 * sd(datos_lim$log_ingreso_hora) / length(datos_lim$log_ingreso_hora)^(1/3)
num_binwidth <- round(x = num_binwidth, digits = 2)
b <- ggplot(datos_lim, aes(x = log_ingreso_hora)) +
geom_histogram(mapping = aes(y = (after_stat(count))/sum(after_stat(count))),
color ="#FFFFFF", fill= "#3a5e8cFF", show.legend = FALSE, na.rm = TRUE,
binwidth = num_binwidth, linewidth = 0.2, alpha = 0.8, closed = 'left') +
scale_y_continuous(expand = expansion(mult = c(0, 0.05)),
labels = scales::label_number(scale = 100)) +
scale_x_continuous(expand = expansion(mult = c(0, 0)), limits = c(0, NA)) +
geom_vline(xintercept = median(datos_lim$log_ingreso_hora, na.rm = TRUE), color = 'green', linetype = 'dashed') +
geom_vline(xintercept = mean(datos_lim$log_ingreso_hora, na.rm = TRUE), color = 'red', linetype = 'dashed') +
labs(x = "Log Ingreso Por hora", y = "Percent (%)") +
theme_classic()
grid.arrange(a,b, nrow = 2)
# CARET
set.seed(10101)  # Set set for replicability purposes
inTrain <- createDataPartition(
y = datos_lim$ingreso_hora_1,  ## the outcome data are needed
p = .70, ## The percentage of training data
list = FALSE
)
training <- datos_lim |> filter(row_number() %in% inTrain)
testing  <- datos_lim |> filter(!(row_number() %in% inTrain))
# Create data for visualization
split_data <- data.frame(
Split = factor(c("Training", "Testing")),
Count = c(nrow(training), nrow(testing)),
Percentage = c(nrow(training)/nrow(datos_lim)*100, nrow(testing)/nrow(datos_lim)*100)
)
# Create the visualization
ggplot(split_data, aes(x = Split, y = Count)) +
geom_bar(stat = "identity", fill = "darkblue", width = 0.5) +
geom_text(aes(label = paste0(round(Percentage, 1), "%\n(n=", Count, ")")),
vjust = -0.5, color = "black", size = 4) +
labs(title = "Train-Test Split Distribution",
y = "Number of Observations",
x = "") +
scale_y_continuous(expand = expansion(mult = c(0, 0.2))) + # Add some space for labels
theme_classic()
skim(datos_lim)
skim(datos_lim)
summary(datos_lim)
data_summary(datos_lim)
sapply(datos_lim, is.numeric)
sapply(datos_lim, class)
rm(inTrain)
rm(training)
rm(testing)
rm(train)
rm(test)
# CARET
set.seed(10101)  # Set set for replicability purposes
inTrain <- createDataPartition(
y = datos_lim$log_ingreso_hora,  ## the outcome data are needed
p = .70, ## The percentage of training data
list = FALSE
)
training <- datos_lim |> filter(row_number() %in% inTrain)
testing  <- datos_lim |> filter(!(row_number() %in% inTrain))
# Create data for visualization
split_data <- data.frame(
Split = factor(c("Training", "Testing")),
Count = c(nrow(training), nrow(testing)),
Percentage = c(nrow(training)/nrow(datos_lim)*100, nrow(testing)/nrow(datos_lim)*100)
)
# Create the visualization
ggplot(split_data, aes(x = Split, y = Count)) +
geom_bar(stat = "identity", fill = "darkblue", width = 0.5) +
geom_text(aes(label = paste0(round(Percentage, 1), "%\n(n=", Count, ")")),
vjust = -0.5, color = "black", size = 4) +
labs(title = "Train-Test Split Distribution",
y = "Number of Observations",
x = "") +
scale_y_continuous(expand = expansion(mult = c(0, 0.2))) + # Add some space for labels
theme_classic()
form1 <- log_ingreso_hora ~ sex
form1 <- lm((log_ingreso_hora) ~ sex, data = training)
predictions <- predict(object = modelo1a, newdata = testing)
score1a<- RMSE(pred = predictions, obs = testing$log_ingreso_hora )
score1a
form1 <- log_ingreso_hora ~ sex
modelo1a <- lm((log_ingreso_hora) ~ sex, data = training)
predictions <- predict(object = modelo1a, newdata = testing)
score1a<- RMSE(pred = predictions, obs = testing$log_ingreso_hora )
score1a
form_2 <- log_ingreso_hora ~ ~ sex + age + I(age^2) + max_educ_level +
oficio + formal + size_firm + hours_work_usual
modelo2a <- lm(form_2,
data = training )
predictions <- predict(object = modelo2a, newdata = testing)
score2a <- RMSE(pred = predictions, obs = testing$log_ingreso_hora )
score2a
form_2 <- log_ingreso_hora ~ sex + age + I(age^2) + max_educ_level +
oficio + formal + size_firm + hours_work_usual
modelo2a <- lm(form_2,
data = training )
predictions <- predict(object = modelo2a, newdata = testing)
score2a <- RMSE(pred = predictions, obs = testing$log_ingreso_hora )
score2a
form_3 <- log_ingreso_hora ~ oficio + formal + cuenta_propia
modelo3a <- lm(form_3,
data = training )
predictions <- predict(object = modelo3a, newdata = testing)
score3a <- RMSE(pred = predictions, obs = testing$log_ingreso_hora )
score3a
form_2 <- log_ingreso_hora ~ sex + age + I(age^2) + max_educ_level +
oficio + formal + size_firm + hours_work_usual
modelo2a <- lm(form_2,
data = training )
predictions <- predict(object = modelo2a, newdata = testing)
score2a <- RMSE(pred = predictions, obs = testing$log_ingreso_hora )
score2a
rm(form1)
rm(form2)
rm(form_2)
rm(form_3)
rm(modelo1a)
rm(modelo2a)
rm(modelo3a)
rm(score1a)
rm(score2a)
rm(score3a)
form1 <- log_ingreso_hora ~ age + I(age^2)
modelo1a <- lm(log_ingreso_hora ~ age + I(age^2), data = training)
predictions <- predict(object = modelo1a, newdata = testing)
score1a<- RMSE(pred = predictions, obs = testing$log_ingreso_hora )
score1a
rm(form1)
form_1 <- log_ingreso_hora ~ age + I(age^2)
modelo1a <- lm(log_ingreso_hora ~ age + I(age^2), data = training)
predictions <- predict(object = modelo1a, newdata = testing)
score1a<- RMSE(pred = predictions, obs = testing$log_ingreso_hora )
score1a
rm(form_1)
form_1 <- log_ingreso_hora ~ age + I(age^2)
modelo1a <- lm(form_1,
data = training)
predictions <- predict(object = modelo1a, newdata = testing)
score1a<- RMSE(pred = predictions, obs = testing$log_ingreso_hora )
score1a
form_2 <- log_ingreso_hora ~ sex
modelo2a <- lm(form_2,
data = training )
predictions <- predict(object = modelo2a, newdata = testing)
score2a<- RMSE(pred = predictions, obs = testing$log_ingreso_hora )
score2a
form_3 <- log_ingreso_hora ~ sex + age + I(age^2) + max_educ_level +
oficio + formal + size_firm + hours_work_usual
modelo3a <- lm(form_3,
data = training )
predictions <- predict(object = modelo3a, newdata = testing)
score3a <- RMSE(pred = predictions, obs = testing$log_ingreso_hora )
score3a
colnames(datos_lim)
rm(form_4)
form_4 <- log_ingreso_hora ~ sex * max_educ_level + age + I(age^2)
modelo4a <- lm(form_4,
data = training )
predictions <- predict(object = modelo4a, newdata = testing)
score4a <- RMSE(pred = predictions, obs = testing$log_ingreso_hora )
score4a
ctrl <- trainControl(
method = "cv", # Method for resampling. It could be CV, repeated CV, LOOCV, and so on.
number = 5) # Number of folds.
set.seed(10101)
modelo1b <- train(
form_1, # Define the functional form (i.e the variable to predict and the features).
data = datos_lim,
method = 'lm', # Algorithm. In this case, linear model.
trControl = ctrl
)
modelo1b
modelo1b$resample
score1b<- mean(modelo1b$resample$RMSE)
score1b
set.seed(10101)
modelo2b <- train(form_2,
data = db,
method = 'lm',
metric= "RMSE",
trControl= ctrl)
modelo2b
set.seed(10101)
modelo2b <- train(form_2,
data = datos_lim,
method = 'lm',
metric= "RMSE",
trControl= ctrl)
modelo2b
score2b<- mean(modelo2b$resample$RMSE)
score2b
set.seed(10101)
modelo3b <- train(form_3,
data = datos_lim,
method = 'lm',
trControl= ctrl)
set.seed(10101)
modelo3b <- train(form_3,
data = datos_lim,
method = 'lm',
metric= "RMSE",
trControl= ctrl)
set.seed(10101)
modelo1b <- train(
form_1, # Define the functional form (i.e the variable to predict and the features).
data = datos_lim,
method = 'lm', # Algorithm. In this case, linear model.
trControl = ctrl
)
modelo1b
modelo1b$resample
score1b<- mean(modelo1b$resample$RMSE)
score1b
set.seed(10101)
modelo2b <- train(form_2,
data = datos_lim,
method = 'lm',
metric= "RMSE",
trControl= ctrl)
modelo2b
score2b<- mean(modelo2b$resample$RMSE)
score2b
set.seed(10101)
modelo3b <- train(form_3,
data = datos_lim,
method = 'lm',
trControl= ctrl)
set.seed(10101)
modelo3b <- train(form_3,
data = datos_lim,
method = 'lm',
metric= "RMSE",
trControl= ctrl)
set.seed(10101)
modelo3b <- train(form_3,
data = datos_lim,
method = 'lm',
metric = "RMSE",
trControl= ctrl)
set.seed(10101)
modelo3b <- train(form_3,
data = datos_lim,
method = 'lm',
metric = "RMSE",
trControl = ctrl
)
set.seed(10101)
modelo2b <- train(form_2,
data = datos_lim,
method = 'lm',
metric= "RMSE",
trControl= ctrl)
modelo2b
set.seed(10101)
modelo1b <- train(
form_1, # Define the functional form (i.e the variable to predict and the features).
data = datos_lim,
method = 'lm', # Algorithm. In this case, linear model.
trControl = ctrl
)
modelo1b
set.seed(10101)
modelo1b <- train(
form_1, # Define the functional form (i.e the variable to predict and the features).
data = datos_lim,
method = 'lm', # Algorithm. In this case, linear model.
metrics = "RMSE",
trControl = ctrl
)
modelo1b
set.seed(10101)
modelo1b <- train(
form_1, # Define the functional form (i.e the variable to predict and the features).
data = datos_lim,
method = 'lm', # Algorithm. In this case, linear model.
trControl = ctrl
)
modelo1b
set.seed(10101)
modelo2b <- train(form_2,
data = datos_lim,
method = 'lm',
trControl= ctrl)
modelo2b
score2b<- mean(modelo2b$resample$RMSE)
score2b
set.seed(10101)
modelo3b <- train(form_3,
data = datos_lim,
method = 'lm',
trControl = ctrl)
set.seed(10101)
modelo3b <- train(form_3,
data = datos_lim,
method = 'lm',
trControl = ctrl)
form_3
is.na(datos_lim)
colSums(is.na(datos_lim))
form_3
hist(datos_lim$max_educ_level)
hist(datos_lim$max_educ_level)
hist(datos_lim$max_educ_level)
str(datos_lim)
# Calcular la moda (nivel mÃ¡s frecuente)
moda <- names(sort(table(datos_lim$max_educ_level), decreasing = TRUE))[1]
# Reemplazar los NA por la moda
datos_lim$max_educ_level <- as.character(datos_lim$max_educ_level)
datos_lim$max_educ_level[is.na(datos_lim$max_educ_level)] <- moda
datos_lim$max_educ_level <- as.factor(datos_lim$max_educ_level)
set.seed(10101)
modelo3b <- train(form_3,
data = datos_lim,
method = 'lm',
trControl = ctrl)
modelo3b
score3b<- mean(modelo3b$resample$RMSE)
score3b
set.seed(69205)
modelo4b <- train(form_4,
data = db,
method = 'lm',
trControl= ctrl)
modelo4b
set.seed(69205)
modelo4b <- train(form_4,
data = datos_lim,
method = 'lm',
trControl= ctrl)
modelo4b
score4b<- mean(modelo4b$resample$RMSE)
score4b
## Store the RMSE in dataframe
scores<- data.frame( Model= c(1, 2, 3, 4),
RMSE_vsa= c(score1a, score2a, score3a, score4a),
RMSE_kfold= c(score1b, score2b, score3b, score4b),
)
head(scores)
## Store the RMSE in dataframe
scores <- data.frame(Model= c(1, 2, 3, 4),
RMSE_vsa= c(score1a, score2a, score3a, score4a),
RMSE_kfold= c(score1b, score2b, score3b, score4b)
)
head(scores)
## RUN THE MODEL WITH ALL OBS
full_model <- lm(form_3,
data = datos_lim)
X<- model.matrix(full_model)
y <- model.response(model.frame(full_model))
beta_hat <- full_model$coefficients
## Calculate the inverse of  (X'X), call it G_inv
G_inv<- solve(t(X)%*%X)
## and 1/1-hi
vec<- 1/(1-hatvalues(full_model))
N <- nrow(X)  # Number of observations
LOO <- numeric(N)  # To store the errors
# Loop over each observation
for (i in 1:N) {
# get the new beta
new_beta<- beta_hat  - vec[i] * G_inv %*% as.vector(X[i, ]) * full_model$residuals[i]
## get the new error
new_error<- (y[i]- (X[i, ] %*% new_beta))^2
LOO[i]<-  new_error
}
looCV_error <- mean(LOO)
sqrt(looCV_error)
## RUN THE MODEL WITH ALL OBS
full_model <- lm(form_3,
data = datos_lim)
X<- model.matrix(full_model)
y <- model.response(model.frame(full_model))
beta_hat <- full_model$coefficients
## Calculate the inverse of  (X'X), call it G_inv
G_inv<- solve(t(X)%*%X)
## and 1/1-hi
vec<- 1/(1-hatvalues(full_model))
N <- nrow(X)  # Number of observations
LOO <- numeric(N)  # To store the errors
# Loop over each observation
for (i in 1:N) {
# get the new beta
new_beta<- beta_hat  - vec[i] * G_inv %*% as.vector(X[i, ]) * full_model$residuals[i]
## get the new error
new_error<- (y[i]- (X[i, ] %*% new_beta))^2
LOO[i]<-  new_error
}
looCV_error <- mean(LOO)
sqrt(looCV_error)
sqrt(looCV_error)
looCV_error <- mean(LOO)
sqrt(looCV_error)
## RUN THE MODEL WITH ALL OBS
full_model <- lm(form_3,
data = datos_lim)
X <- model.matrix(full_model)
y <- model.response(model.frame(full_model))
X <- model.matrix(full_model)
beta_hat <- full_model$coefficients
## Calculate the inverse of  (X'X), call it G_inv
G_inv <- solve(t(X)%*%X)
## and 1/1-hi
vec <- 1/(1-hatvalues(full_model))
N <- nrow(X)  # Number of observations
LOO <- numeric(N)  # To store the errors
# Loop over each observation
for (i in 1:N) {
# get the new beta
new_beta<- beta_hat  - vec[i] * G_inv %*% as.vector(X[i, ]) * full_model$residuals[i]
## get the new error
new_error<- (y[i]- (X[i, ] %*% new_beta))^2
LOO[i]<-  new_error
}
looCV_error <- mean(LOO)
sqrt(looCV_error)
rm(full_model)
rm(x)
rm(X)
rm(Y)
rm(beta_hat)
rm(G_inv)
rm(vec)
rm(N)
rm(LOO)
rm(looCV_error)
## RUN THE MODEL WITH ALL OBS
full_model <- lm(form_1,
data = datos_lim)
X <- model.matrix(full_model)
y <- model.response(model.frame(full_model))
beta_hat <- full_model$coefficients
## Calculate the inverse of  (X'X), call it G_inv
G_inv <- solve(t(X)%*%X)
## and 1/1-hi
vec <- 1/(1-hatvalues(full_model))
N <- nrow(X)  # Number of observations
LOO <- numeric(N)  # To store the errors
# Loop over each observation
for (i in 1:N) {
# get the new beta
new_beta<- beta_hat  - vec[i] * G_inv %*% as.vector(X[i, ]) * full_model$residuals[i]
## get the new error
new_error<- (y[i]- (X[i, ] %*% new_beta))^2
LOO[i]<-  new_error
}
looCV_error <- mean(LOO)
sqrt(looCV_error)
